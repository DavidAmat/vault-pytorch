{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1ca1e7-14b5-496e-bb2a-fbeb71c5999e",
   "metadata": {},
   "source": [
    "# LightGCN Book-Crossing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17723717-1b5a-40bd-a772-9a799aad624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements_cuda.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c123ecdc-4125-414d-b0ed-c945070fd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ed0ad3-7d9b-4914-9cf0-920f0327cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch-geometric==2.2.0\n",
    "#!pip install torch-scatter==2.1.0 -f https://data.pyg.org/whl/torch-1.13.0%2Bcu116.html\n",
    "#!pip install torch-sparse==0.6.16 -f https://data.pyg.org/whl/torch-1.13.0%2Bcu116.html\n",
    "# !pip install torch-cluster==1.6.0 -f https://data.pyg.org/whl/torch-1.13.0%2Bcu116.html\n",
    "# !pip install torch-spline-conv==1.2.1 -f https://data.pyg.org/whl/torch-1.13.0%2Bcu116.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c63021-92a2-4579-8c1d-89d37c1b688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as jp\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model import LightGCN\n",
    "from torch import optim\n",
    "import tqdm\n",
    "from utils import bpr_loss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a3de5c-463c-4fba-9d38-1b76f3ae317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py:282: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Clean up GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Reset GPU device to release all resources\n",
    "torch.cuda.reset_max_memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71540418-cb69-40c7-930a-52f21c41ae6f",
   "metadata": {},
   "source": [
    "## Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda3725-46e9-460f-b7e2-c4b8dc2c85a9",
   "metadata": {},
   "source": [
    "- From Kaggle: https://www.kaggle.com/datasets/somnambwl/bookcrossing-dataset/\n",
    "- Destination path: /Users/davidamat/Documents/david/learning/graph/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b580e34b-f3b4-43e1-99d7-0d9f78c67a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec013f70-f9e8-41db-b754-fb3e8f76c2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_702/3612776475.py:7: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_users, sep=';', encoding='latin-1')\n"
     ]
    }
   ],
   "source": [
    "path_ratings = jp(path_data, 'Ratings.csv')\n",
    "path_users = jp(path_data, 'Users.csv')\n",
    "path_books = jp(path_data, 'Books.csv')\n",
    "\n",
    "\n",
    "ratings = pd.read_csv(path_ratings, sep=';', encoding='latin-1')\n",
    "users = pd.read_csv(path_users, sep=';', encoding='latin-1')\n",
    "books = pd.read_csv(path_books, sep=';', encoding='latin-1', on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5869b1b-bc6a-4dc5-914f-a889f7525f34",
   "metadata": {},
   "source": [
    "## Preprocessing the Book-Crossing dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a28a8df-5ab7-468d-b377-2b6cae010867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 19557\n",
      "Items: 56913\n",
      "Total Users and Items: 76470\n"
     ]
    }
   ],
   "source": [
    "# Identifiers\n",
    "books_ids = books['ISBN'].unique()\n",
    "user_ids = users['User-ID'].unique()\n",
    "\n",
    "# Ratings as df\n",
    "df = ratings.copy()\n",
    "\n",
    "# Mask only ratings of books and users that appear on the master tables of each one\n",
    "mask_books_ids = df['ISBN'].isin(books_ids)\n",
    "mask_users_ids = df['User-ID'].isin(user_ids)\n",
    "df = df.loc[mask_books_ids & mask_users_ids]\n",
    "\n",
    "# Keep the 100k highest ratings\n",
    "df = df[df['Rating'] >= 8].iloc[:100000]\n",
    "\n",
    "# Create mappings\n",
    "user_mapping = {userid: i for i, userid in enumerate(df['User-ID'].unique())}\n",
    "item_mapping = {isbn: i for i, isbn in enumerate(df['ISBN'].unique())}\n",
    "\n",
    "# Count users and items\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)\n",
    "num_total = num_users + num_items\n",
    "\n",
    "# Construct the IDS columns\n",
    "df_ids = df.copy()\n",
    "df_ids[\"u_id\"] = df_ids[\"User-ID\"].map(user_mapping)\n",
    "df_ids[\"b_id\"] = df_ids[\"ISBN\"].map(item_mapping)\n",
    "\n",
    "print(\"Users:\", num_users)\n",
    "print(\"Items:\", num_items)\n",
    "print(\"Total Users and Items:\", num_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c102de-ec19-482f-8677-586e7a87d45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9586</th>\n",
       "      <td>12</td>\n",
       "      <td>1879384493</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9591</th>\n",
       "      <td>16</td>\n",
       "      <td>0345402871</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9607</th>\n",
       "      <td>26</td>\n",
       "      <td>0446310786</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9608</th>\n",
       "      <td>26</td>\n",
       "      <td>0449005615</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9609</th>\n",
       "      <td>32</td>\n",
       "      <td>0060168013</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User-ID        ISBN  Rating\n",
       "9586       12  1879384493      10\n",
       "9591       16  0345402871       9\n",
       "9607       26  0446310786      10\n",
       "9608       26  0449005615       9\n",
       "9609       32  0060168013       8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f82c581-25df-4ebb-b61c-091ab6817aeb",
   "metadata": {},
   "source": [
    "## Edge Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab87f406-80ca-4fbc-8634-af51722140e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 19557\n",
      "Num items: 56913\n",
      "Num nodes: 76470\n"
     ]
    }
   ],
   "source": [
    "# Build the adjacency matrix based on user ratings:\n",
    "\n",
    "# 1) Take the column of users and convert their ID into the internal ID\n",
    "user_ids = torch.LongTensor([user_mapping[i] for i in df['User-ID']])\n",
    "\n",
    "# 2) Take the column of items and convert their ID into the internal ID\n",
    "item_ids = torch.LongTensor([item_mapping[i] for i in df['ISBN']])\n",
    "\n",
    "# Number of users and items\n",
    "num_users = len(user_ids.unique())\n",
    "num_items = len(item_ids.unique())\n",
    "num_nodes = num_users + num_items\n",
    "\n",
    "# 3) Create the edge tensor as the relationship between 1) and 2) (they come from ratings matrix)\n",
    "edge_index = torch.stack((user_ids, item_ids))\n",
    "\n",
    "print(\"Num users:\", num_users)\n",
    "print(\"Num items:\", num_items)\n",
    "print(\"Num nodes:\", num_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a64018-7962-4417-972c-a767fa78a629",
   "metadata": {},
   "source": [
    "## Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f31267ce-bc1b-45a0-8836-92571e71e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training, validation, and test adjacency matrices\n",
    "train_index, test_index = train_test_split(range(len(df)), test_size=0.2, random_state=0)\n",
    "val_index, test_index = train_test_split(test_index, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec8ee21-afbc-459b-ab4d-74d1bc86e65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0, 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 24, 27]\n",
      "Test: [3, 14, 17, 23, 34, 48, 52, 56, 60, 63, 65, 68, 79, 109, 110, 117, 157, 165, 187, 196]\n",
      "Valid: [6, 9, 25, 26, 36, 41, 51, 54, 69, 72, 90, 105, 119, 121, 125, 128, 133, 151, 156, 166]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", sorted(train_index)[:20])\n",
    "print(\"Test:\", sorted(test_index)[:20])\n",
    "print(\"Valid:\", sorted(val_index)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5305b31-0a32-4913-9184-a7ce0a64d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge indices\n",
    "train_edge_index = edge_index[:, train_index]\n",
    "val_edge_index = edge_index[:, val_index]\n",
    "test_edge_index = edge_index[:, test_index]\n",
    "\n",
    "# Edge values\n",
    "train_edge_values = torch.ones_like(train_edge_index[0,:])\n",
    "valid_edge_values = torch.ones_like(val_edge_index[0,:])\n",
    "test_edge_values = torch.ones_like(test_edge_index[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8522b-f502-4ad6-ae68-6f4a5cea4718",
   "metadata": {},
   "source": [
    "## LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "748ab7a2-e333-4e0a-9495-bd314ad83bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per epoch: 5000\n"
     ]
    }
   ],
   "source": [
    "K = 20\n",
    "K_LIST = [5,10,20,50,100]\n",
    "LAMBDA = 1e-6\n",
    "BATCH_SIZE = 16\n",
    "NUM_LAYERS = 4\n",
    "DIM_EMBEDDING = 64\n",
    "EPOCHS = 31\n",
    "\n",
    "# Side computations\n",
    "n_batch = int(len(train_index)/BATCH_SIZE)\n",
    "print(\"Number of batches per epoch:\", n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29cde01f-4f41-4992-987c-d5bd526f5304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/02-lightgcn/model.py:117: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -0.5).flatten()\n",
      "/notebooks/02-lightgcn/model.py:74: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  return sparse_tensor.to_sparse_csr()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.09 s, sys: 881 ms, total: 2.97 s\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LightGCN(\n",
    "    num_users=num_users, \n",
    "    num_items=num_items, \n",
    "    edge_index=train_edge_index,\n",
    "    edge_values=train_edge_values,\n",
    "    edge_index_val=val_edge_index,\n",
    "    edge_values_val=valid_edge_values,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dim_h=DIM_EMBEDDING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49700b-5388-46ce-921f-3e58e8f163fc",
   "metadata": {},
   "source": [
    "## To Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3674014c-3a69-44bd-ba53-601272b5c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, capturable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d93d8df-ab0d-4180-89bf-ee0ff1578ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory items embeddings: 14.57 MB\n",
      "Memory user embeddings: 5.01 MB\n"
     ]
    }
   ],
   "source": [
    "x = model.emb_items.weight.element_size() * model.emb_items.weight.nelement() / 1e6\n",
    "y = model.emb_users.weight.element_size() * model.emb_users.weight.nelement() / 1e6\n",
    "print(f\"Memory items embeddings: {x:.2f} MB\")\n",
    "print(f\"Memory user embeddings: {y:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1810155a-f9af-45d1-99b7-5cfeb5a443c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56913, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.emb_items.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aca43b8-add5-4613-8966-653d44fbf823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19557, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.emb_users.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de67234-93b2-40d6-92aa-85991b15045a",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c79346-ce11-4c55-9531-111430fa91eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_702/2228796846.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for _ in tqdm.tqdm_notebook(range(n_batch), leave=False):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Epoch - 0 \n",
      "Precision@20 - 9.19963201471941e-05 \n",
      "Recall@20 - 0.0008 \n",
      "NDCG@20 - 0.0006207354017533362\n",
      "************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3748b27f7043a689cb5dcc04e77224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metrics loss\n",
    "l_metrics = []\n",
    "\n",
    "n_batch = int(len(train_index)/BATCH_SIZE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    for _ in tqdm.tqdm_notebook(range(n_batch), leave=False):\n",
    "        # Forward pass\n",
    "        embf_users, emb0_users, embf_items, emb0_items = model.forward()\n",
    "        \n",
    "        # Getting sample indices\n",
    "        user_indices, pos_item_indices, neg_item_indices = model.sample_mini_batch()\n",
    "        \n",
    "        # Applying sample indices\n",
    "        s_embf_users, s_emb0_users = embf_users[user_indices], emb0_users[user_indices]\n",
    "        s_embf_items_pos, s_emb0_items_pos = embf_items[pos_item_indices], emb0_items[pos_item_indices]\n",
    "        s_embf_items_neg, s_emb0_items_neg = embf_items[neg_item_indices], emb0_items[neg_item_indices]\n",
    "        \n",
    "        # Loss computation\n",
    "        train_loss = bpr_loss(\n",
    "            s_embf_users, s_emb0_users, \n",
    "            s_embf_items_pos, s_emb0_items_pos, \n",
    "            s_embf_items_neg, s_emb0_items_neg,\n",
    "            LAMBDA=LAMBDA\n",
    "        )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # End of epoch\n",
    "    \n",
    "    # Start validation if multiple of 5\n",
    "    if epoch % 5 == 0:\n",
    "        \n",
    "        # Precision and recall on validation (generate all items recs)\n",
    "        l_epoch_metrics = model.get_val_metrics(\n",
    "            epoch=epoch, \n",
    "            topk_recs=max(K_LIST),\n",
    "            k_list=K_LIST\n",
    "        )\n",
    "        l_metrics.extend(l_epoch_metrics)\n",
    "        \n",
    "        # If we want to print Prec@K with K=2, we will select the second item of k_list\n",
    "        k_print = 20\n",
    "        idx_k = np.where(np.array(K_LIST)==k_print)[0][0]\n",
    "        prec = l_epoch_metrics[idx_k][-3]  # precision\n",
    "        rec = l_epoch_metrics[idx_k][-2]  # recall (since -1 is for ndcg)\n",
    "        ndcg = l_epoch_metrics[idx_k][-1]\n",
    "        print(\"************************************************************\")\n",
    "        print(f\"Epoch - {epoch}\", \n",
    "              f\"\\nPrecision@{k_print} - {prec}\", \n",
    "              f\"\\nRecall@{k_print} - {rec}\",\n",
    "              f\"\\nNDCG@{k_print} - {ndcg}\",\n",
    "             )\n",
    "        print(\"************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70ffac-5695-45ef-a956-4b7bfdc971cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_epoch = pd.DataFrame(l_metrics, columns=[\"epoch\", \"K\", \"TP\", \"FP\", \"P\", \"precision\", \"recall\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f8d67-f61e-4c24-aebf-441e188498b9",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a457712-1065-4b76-827e-7b98f5c62e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_model = \"save_model\"\n",
    "model_name_weights = jp(folder_model, f\"lightgcn_books_v1_e{EPOCHS}_weights.pth\")\n",
    "model_name_pickle = jp(folder_model, f\"lightgcn_books_v1_e{EPOCHS}_pickle.pth\")\n",
    "model_performance_train = jp(\"model_performance\", f\"metrics_lightgcn_books_v1_e{EPOCHS}_weights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037287e1-ec7d-47fa-935e-d2cf102ab1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_epoch.to_parquet(\n",
    "    model_performance_train,\n",
    "    engine=\"pyarrow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b1e7487-4d5a-4d1a-8edf-bad550033adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_name_weights)\n",
    "torch.save(model, model_name_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83cf6eff-cd82-4661-9a96-5fd3862ea874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xx = torch.load(model_name_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca36b96-2ca3-4d8a-a04c-cad7e00483b3",
   "metadata": {},
   "source": [
    "# Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f822c-e96b-435f-aadf-8c7c4dd2b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and recall on validation (generate all items recs)\n",
    "l_epoch_metrics = model.get_val_metrics(\n",
    "    epoch=epoch, \n",
    "    topk_recs=model.num_items,\n",
    "    k_list=K_LIST\n",
    ")\n",
    "l_metrics.append(l_epoch_metrics)\n",
    "\n",
    "\n",
    "# If we want to print Prec@K with K=2, we will select the second item of k_list\n",
    "k_print = 10\n",
    "idx_k = np.where(np.array(K_LIST)==k_print)[0][0]\n",
    "prec = l_epoch_metrics[idx_k][-2]\n",
    "rec = l_epoch_metrics[idx_k][-1]\n",
    "\n",
    "print(f\"Epoch - {epoch}\", f\"Precision@{k_print} - {prec}\", f\"Recall@{k_print} - {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a027a0-c518-4b22-9ad7-e984ec9e4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_metrics_epoch = pd.DataFrame(l_metrics, columns=[\"epoch\", \"K\", \"TP\", \"FP\", \"P\", \"precision\", \"recall\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856516c-968b-45b2-af47-7df71d8c9cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
